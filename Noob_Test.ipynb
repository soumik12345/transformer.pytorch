{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from secret import WANDB_API_KEY\n",
    "from src.model import Transformer\n",
    "from src.utils import subsequent_mask\n",
    "from src.training import (\n",
    "    Batch, NoamOptimizer,\n",
    "    LabelSmoothing, train_step\n",
    ")\n",
    "from matplotlib import pyplot as plt\n",
    "from src.utils import subsequent_mask\n",
    "from src.blocks import PositionalEncoding\n",
    "from src.training import NoamOptimizer, LabelSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/19soumik-rakshit96/transformer-pytorch\" target=\"_blank\">https://app.wandb.ai/19soumik-rakshit96/transformer-pytorch</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/19soumik-rakshit96/transformer-pytorch/runs/19n8lu61\" target=\"_blank\">https://app.wandb.ai/19soumik-rakshit96/transformer-pytorch/runs/19n8lu61</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/19soumik-rakshit96/transformer-pytorch/runs/19n8lu61"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['WANDB_API_KEY'] = WANDB_API_KEY\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'Noob_Test'\n",
    "wandb.init(project=\"transformer-pytorch\", name=\"noob-test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Sanity Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(subsequent_mask(20)[0])\n",
    "plt.title('Test for Subsequent Mask')\n",
    "wandb.log({'Test for Subsequent Mask': plt})\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "pe = PositionalEncoding(20, 0)\n",
    "y = pe.forward(\n",
    "    torch.autograd.Variable(\n",
    "        torch.zeros(1, 100, 20)\n",
    "    )\n",
    ")\n",
    "plt.plot(np.arange(100), y[0, :, 4:8].data.numpy())\n",
    "plt.legend([\"dim %d\" % p for p in [4, 5, 6, 7]])\n",
    "plt.title('Test for Positional Encoding')\n",
    "wandb.log({'Test for Positional Encoding': wandb.Image(plt)})\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = [\n",
    "    NoamOptimizer(512, 1, 4000, None),\n",
    "    NoamOptimizer(512, 1, 8000, None),\n",
    "    NoamOptimizer(256, 1, 4000, None)\n",
    "]\n",
    "plt.plot(\n",
    "    np.arange(1, 20000),\n",
    "    [[opt.rate(i) for opt in optimizers] for i in range(1, 20000)]\n",
    ")\n",
    "plt.legend([\"512:4000\", \"512:8000\", \"256:4000\"])\n",
    "plt.title('Test for Noam Learning Rate Policy')\n",
    "wandb.log({'Test for Noam Learning Rate Policy': wandb.Image(plt)})\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "criterion = LabelSmoothing(5, 0, 0.4)\n",
    "predict = torch.FloatTensor(\n",
    "    [\n",
    "        [0, 0.2, 0.7, 0.1, 0],\n",
    "        [0, 0.2, 0.7, 0.1, 0],\n",
    "        [0, 0.2, 0.7, 0.1, 0]\n",
    "    ]\n",
    ")\n",
    "v = criterion(\n",
    "    torch.autograd.Variable(predict.log()),\n",
    "    torch.autograd.Variable(\n",
    "        torch.LongTensor([2, 1, 0])\n",
    "    )\n",
    ")\n",
    "plt.imshow(criterion.true_dist)\n",
    "plt.title('Test for Label Smoothing (Target Distribution)')\n",
    "wandb.log({'Test for Label Smoothing (Target Distribution)': plt})\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error uploading \"config.yaml\": FileNotFoundError, [Errno 2] No such file or directory: '/tmp/tmpnr0jv7uqwandb/2bv8aijp-config.yaml'\n"
     ]
    }
   ],
   "source": [
    "criterion = LabelSmoothing(5, 0, 0.1)\n",
    "\n",
    "def loss(x):\n",
    "    d = x + 3 * 1\n",
    "    prediction = torch.FloatTensor([[0, x / d, 1 / d, 1 / d, 1 / d], ])\n",
    "    return criterion(\n",
    "        torch.autograd.Variable(prediction.log()),\n",
    "        torch.autograd.Variable(torch.LongTensor([1]))).data.item()\n",
    "\n",
    "plt.plot(np.arange(1, 100), [loss(x) for x in range(1, 100)])\n",
    "plt.title('Test for Label Smoothing (Regularization)')\n",
    "wandb.log({'Test for Label Smoothing (Regularization)': wandb.Image(plt)})\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noob Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(V, batch, nbatches):\n",
    "    for i in range(nbatches):\n",
    "        data = torch.from_numpy(\n",
    "            np.random.randint(\n",
    "                1, V, size=(batch, 10)\n",
    "            )\n",
    "        )\n",
    "        data[:, 0] = 1\n",
    "        src = torch.autograd.Variable(data, requires_grad=False)\n",
    "        tgt = torch.autograd.Variable(data, requires_grad=False)\n",
    "        yield Batch(src, tgt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    \n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(\n",
    "            x.contiguous().view(-1, x.size(-1)),\n",
    "            y.contiguous().view(-1)\n",
    "        ) / norm\n",
    "        loss.backward()\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "        return loss.data.item() * norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/transformer.pytorch/src/model.py:76: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(p)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7f56f9ed5940>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = 11\n",
    "model = Transformer(V, V, n=2)\n",
    "criterion = LabelSmoothing(\n",
    "    size=V, padding_index=0, smoothing=0.0\n",
    ")\n",
    "model_opt = NoamOptimizer(\n",
    "    model.source_embedding[0].d_model, 1, 400,\n",
    "    torch.optim.Adam(\n",
    "        model.parameters(), lr=0,\n",
    "        betas=(0.9, 0.98), eps=1e-9\n",
    "    )\n",
    ")\n",
    "\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:07,  2.70it/s]\n",
      "5it [00:01,  4.12it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:06,  3.12it/s]\n",
      "5it [00:01,  4.58it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:06,  3.05it/s]\n",
      "5it [00:01,  3.98it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:06,  3.13it/s]\n",
      "5it [00:01,  2.93it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:06,  2.90it/s]\n",
      "5it [00:01,  3.14it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:06,  2.93it/s]\n",
      "5it [00:01,  3.84it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:06,  3.02it/s]\n",
      "5it [00:01,  4.18it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:06,  2.96it/s]\n",
      "5it [00:01,  2.84it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:03,  3.07it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    print('Epoch:', (epoch + 1))\n",
    "    model.train()\n",
    "    train_step(\n",
    "        data_gen(V, 30, 20), model, \n",
    "        SimpleLossCompute(\n",
    "            model.generator,\n",
    "            criterion, model_opt\n",
    "        ), log_on_wandb=True\n",
    "    )\n",
    "    model.eval()\n",
    "    train_step(\n",
    "        data_gen(V, 30, 5), model, \n",
    "        SimpleLossCompute(\n",
    "            model.generator,\n",
    "            criterion, None\n",
    "        ), log_on_wandb=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, source, source_mask, max_length, start_symbol):\n",
    "    memory = model.encode(source, source_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(source.data)\n",
    "    for i in range(max_length - 1):\n",
    "        out = model.decode(\n",
    "            memory, source_mask,\n",
    "            torch.autograd.Variable(ys), \n",
    "            torch.autograd.Variable(\n",
    "                subsequent_mask(ys.size(1)).type_as(source.data)\n",
    "            )\n",
    "        )\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat(\n",
    "            [ys, torch.ones(1, 1).type_as(source.data).fill_(next_word)], dim=1\n",
    "        )\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "source = torch.autograd.Variable(\n",
    "    torch.LongTensor(\n",
    "        [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]]\n",
    "    )\n",
    ")\n",
    "source_mask = torch.autograd.Variable(\n",
    "    torch.ones(1, 1, 10)\n",
    ")\n",
    "print(\n",
    "    greedy_decode(\n",
    "        model, source, source_mask,\n",
    "        max_length=10, start_symbol=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
