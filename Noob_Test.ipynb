{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wandb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b304df018500>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wandb'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from secret import WANDB_API_KEY\n",
    "from src.model import Transformer\n",
    "from src.utils import subsequent_mask\n",
    "from src.training import (\n",
    "    Batch, NoamOptimizer,\n",
    "    LabelSmoothing, train_step\n",
    ")\n",
    "from sanity_tests import (\n",
    "    test_subsequent_mask, test_positional_encoding, test_noam_lr_policy,\n",
    "    test_label_smoothing_target_distribution, test_label_smoothing_regularization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in ./env/lib/python3.7/site-packages (0.9.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in ./env/lib/python3.7/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: sentry-sdk>=0.4.0 in ./env/lib/python3.7/site-packages (from wandb) (0.14.4)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in ./env/lib/python3.7/site-packages (from wandb) (3.1.3)\n",
      "Requirement already satisfied: gql==0.2.0 in ./env/lib/python3.7/site-packages (from wandb) (0.2.0)\n",
      "Requirement already satisfied: Click>=7.0 in ./env/lib/python3.7/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./env/lib/python3.7/site-packages (from wandb) (5.7.0)\n",
      "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in ./env/lib/python3.7/site-packages (from wandb) (7.352.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in ./env/lib/python3.7/site-packages (from wandb) (2.23.0)\n",
      "Requirement already satisfied: six>=1.10.0 in ./env/lib/python3.7/site-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in ./env/lib/python3.7/site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in ./env/lib/python3.7/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: configparser>=3.8.1 in ./env/lib/python3.7/site-packages (from wandb) (5.0.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in ./env/lib/python3.7/site-packages (from wandb) (5.3.1)\n",
      "Requirement already satisfied: watchdog>=0.8.3 in ./env/lib/python3.7/site-packages (from wandb) (0.10.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in ./env/lib/python3.7/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: urllib3>=1.10.0 in ./env/lib/python3.7/site-packages (from sentry-sdk>=0.4.0->wandb) (1.25.9)\n",
      "Requirement already satisfied: certifi in ./env/lib/python3.7/site-packages (from sentry-sdk>=0.4.0->wandb) (2020.4.5.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./env/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb) (4.0.5)\n",
      "Requirement already satisfied: graphql-core<2,>=0.5.0 in ./env/lib/python3.7/site-packages (from gql==0.2.0->wandb) (1.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in ./env/lib/python3.7/site-packages (from gql==0.2.0->wandb) (2.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in ./env/lib/python3.7/site-packages (from requests>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./env/lib/python3.7/site-packages (from requests>=2.0.0->wandb) (2.9)\n",
      "Requirement already satisfied: pathtools>=0.1.1 in ./env/lib/python3.7/site-packages (from watchdog>=0.8.3->wandb) (0.1.2)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in ./env/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (3.0.4)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(V, batch, nbatches):\n",
    "    for i in range(nbatches):\n",
    "        data = torch.from_numpy(\n",
    "            np.random.randint(\n",
    "                1, V, size=(batch, 10)\n",
    "            )\n",
    "        )\n",
    "        data[:, 0] = 1\n",
    "        src = torch.autograd.Variable(data, requires_grad=False)\n",
    "        tgt = torch.autograd.Variable(data, requires_grad=False)\n",
    "        yield Batch(src, tgt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    \n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(\n",
    "            x.contiguous().view(-1, x.size(-1)),\n",
    "            y.contiguous().view(-1)\n",
    "        ) / norm\n",
    "        loss.backward()\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "        return loss.data.item() * norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumikrakshit/Workspace/transformer.pytorch/src/model.py:76: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(p)\n",
      "/usr/local/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "V = 11\n",
    "model = Transformer(V, V, n=2)\n",
    "criterion = LabelSmoothing(\n",
    "    size=V, padding_index=0, smoothing=0.0\n",
    ")\n",
    "model_opt = NoamOptimizer(\n",
    "    model.source_embedding[0].d_model, 1, 400,\n",
    "    torch.optim.Adam(\n",
    "        model.parameters(), lr=0,\n",
    "        betas=(0.9, 0.98), eps=1e-9\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 3.222836 Tokens per Sec: 356.105133\n",
      "Epoch Step: 1 Loss: 1.898097 Tokens per Sec: 514.855530\n",
      "tensor(1.8864)\n",
      "Epoch Step: 1 Loss: 1.961129 Tokens per Sec: 477.678619\n",
      "Epoch Step: 1 Loss: 1.615044 Tokens per Sec: 545.999451\n",
      "tensor(1.6368)\n",
      "Epoch Step: 1 Loss: 1.881133 Tokens per Sec: 312.640778\n",
      "Epoch Step: 1 Loss: 1.423026 Tokens per Sec: 550.668030\n",
      "tensor(1.4335)\n",
      "Epoch Step: 1 Loss: 1.788222 Tokens per Sec: 462.523651\n",
      "Epoch Step: 1 Loss: 1.237994 Tokens per Sec: 498.938354\n",
      "tensor(1.2300)\n",
      "Epoch Step: 1 Loss: 1.650148 Tokens per Sec: 359.106323\n",
      "Epoch Step: 1 Loss: 0.960283 Tokens per Sec: 471.688324\n",
      "tensor(0.9734)\n",
      "Epoch Step: 1 Loss: 1.151660 Tokens per Sec: 358.550964\n",
      "Epoch Step: 1 Loss: 0.588864 Tokens per Sec: 339.864563\n",
      "tensor(0.6103)\n",
      "Epoch Step: 1 Loss: 0.920910 Tokens per Sec: 410.786011\n",
      "Epoch Step: 1 Loss: 0.376575 Tokens per Sec: 511.768738\n",
      "tensor(0.4024)\n",
      "Epoch Step: 1 Loss: 0.554213 Tokens per Sec: 342.275574\n",
      "Epoch Step: 1 Loss: 0.228428 Tokens per Sec: 427.981476\n",
      "tensor(0.2461)\n",
      "Epoch Step: 1 Loss: 0.494119 Tokens per Sec: 141.509064\n",
      "Epoch Step: 1 Loss: 0.220053 Tokens per Sec: 370.060181\n",
      "tensor(0.1928)\n",
      "Epoch Step: 1 Loss: 0.487329 Tokens per Sec: 343.877258\n",
      "Epoch Step: 1 Loss: 0.125596 Tokens per Sec: 419.193542\n",
      "tensor(0.1224)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    train_step(\n",
    "        data_gen(V, 30, 20), model, \n",
    "        SimpleLossCompute(\n",
    "            model.generator,\n",
    "            criterion, model_opt\n",
    "        )\n",
    "    )\n",
    "    model.eval()\n",
    "    print(\n",
    "        train_step(\n",
    "            data_gen(V, 30, 5), model, \n",
    "            SimpleLossCompute(\n",
    "                model.generator,\n",
    "                criterion, None\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, source, source_mask, max_length, start_symbol):\n",
    "    memory = model.encode(source, source_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(source.data)\n",
    "    for i in range(max_length - 1):\n",
    "        out = model.decode(\n",
    "            memory, source_mask,\n",
    "            torch.autograd.Variable(ys), \n",
    "            torch.autograd.Variable(\n",
    "                subsequent_mask(ys.size(1)).type_as(source.data)\n",
    "            )\n",
    "        )\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat(\n",
    "            [ys, torch.ones(1, 1).type_as(source.data).fill_(next_word)], dim=1\n",
    "        )\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "source = torch.autograd.Variable(\n",
    "    torch.LongTensor(\n",
    "        [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]]\n",
    "    )\n",
    ")\n",
    "source_mask = torch.autograd.Variable(\n",
    "    torch.ones(1, 1, 10)\n",
    ")\n",
    "print(\n",
    "    greedy_decode(\n",
    "        model, source, source_mask,\n",
    "        max_length=10, start_symbol=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
